#!/usr/bin/env python3
"""
Veo API çµæ§‹æ¸¬è©¦ - ä¸éœ€è¦å¯¦éš› Google Cloud èªè­‰
ç”¨æ–¼é©—è­‰ä»£ç¢¼çµæ§‹å’Œ API ç«¯é»æ­£ç¢ºæ€§
"""

import json
from typing import Dict, Any, Optional


class VeoAPIStructureTest:
    """Veo API çµæ§‹æ¸¬è©¦é¡åˆ¥"""
    
    def __init__(self, project_id: str = "test-project", location: str = "us-central1"):
        self.project_id = project_id
        self.location = location
        self.base_url = f"https://{location}-aiplatform.googleapis.com/v1"
        
        # å®˜æ–¹æ”¯æ´çš„æ¨¡å‹æ¸…å–®
        self.supported_models = {
            "veo-2.0-generate-001": {
                "name": "Veo 2.0 GAç‰ˆæœ¬",
                "supports_audio": False,
                "duration_range": [5, 8],
                "default_duration": 8,
                "status": "ç©©å®šç‰ˆæœ¬"
            },
            "veo-2.0-generate-exp": {
                "name": "Veo 2.0 å¯¦é©—ç‰ˆæœ¬",
                "supports_audio": False,
                "supports_reference_images": True,
                "duration_range": [5, 8],
                "default_duration": 8,
                "status": "å¯¦é©—ç‰ˆæœ¬"
            },
            "veo-3.0-generate-001": {
                "name": "Veo 3.0 æ¨™æº–ç‰ˆæœ¬",
                "supports_audio": True,
                "duration_range": [4, 6, 8],
                "default_duration": 8,
                "status": "ç©©å®šç‰ˆæœ¬"
            },
            "veo-3.0-fast-generate-001": {
                "name": "Veo 3.0 å¿«é€Ÿç‰ˆæœ¬",
                "supports_audio": True,
                "duration_range": [4, 6, 8],
                "default_duration": 8,
                "status": "ç©©å®šç‰ˆæœ¬"
            },
            "veo-3.0-generate-preview": {
                "name": "Veo 3.0 é è¦½ç‰ˆæœ¬",
                "supports_audio": True,
                "duration_range": [4, 6, 8],
                "default_duration": 8,
                "status": "é è¦½ç‰ˆæœ¬"
            },
            "veo-3.0-fast-generate-preview": {
                "name": "Veo 3.0 å¿«é€Ÿé è¦½ç‰ˆæœ¬",
                "supports_audio": True,
                "duration_range": [4, 6, 8],
                "default_duration": 8,
                "status": "é è¦½ç‰ˆæœ¬"
            }
        }
    
    def validate_model_support(self) -> Dict[str, Any]:
        """é©—è­‰æ¨¡å‹æ”¯æ´æ¸…å–®"""
        results = {
            "total_models": len(self.supported_models),
            "stable_models": [],
            "preview_models": [],
            "audio_supported_models": [],
            "reference_image_models": []
        }
        
        for model_id, info in self.supported_models.items():
            if info["status"] == "ç©©å®šç‰ˆæœ¬":
                results["stable_models"].append(model_id)
            elif info["status"] in ["é è¦½ç‰ˆæœ¬", "å¯¦é©—ç‰ˆæœ¬"]:
                results["preview_models"].append(model_id)
            
            if info.get("supports_audio", False):
                results["audio_supported_models"].append(model_id)
            
            if info.get("supports_reference_images", False):
                results["reference_image_models"].append(model_id)
        
        return results
    
    def generate_api_endpoint(self, model_id: str) -> str:
        """ç”Ÿæˆ API ç«¯é» URL"""
        if model_id not in self.supported_models:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹: {model_id}")
        
        return f"{self.base_url}/projects/{self.project_id}/locations/{self.location}/publishers/google/models/{model_id}:predictLongRunning"
    
    def generate_polling_endpoint(self, model_id: str) -> str:
        """ç”Ÿæˆè¼ªè©¢ç«¯é» URL"""
        if model_id not in self.supported_models:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹: {model_id}")
        
        return f"{self.base_url}/projects/{self.project_id}/locations/{self.location}/publishers/google/models/{model_id}:fetchPredictOperation"
    
    def create_text_to_video_payload(
        self,
        prompt: str,
        model_id: str,
        **kwargs
    ) -> Dict[str, Any]:
        """å‰µå»ºæ–‡å­—è½‰å½±ç‰‡çš„è«‹æ±‚è¼‰è·"""
        if model_id not in self.supported_models:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹: {model_id}")
        
        model_info = self.supported_models[model_id]
        
        # åŸºæœ¬å¯¦ä¾‹
        instances = [{"prompt": prompt}]
        
        # åŸºæœ¬åƒæ•¸
        parameters = {
            "aspectRatio": kwargs.get("aspect_ratio", "16:9"),
            "durationSeconds": kwargs.get("duration_seconds", model_info["default_duration"]),
            "sampleCount": kwargs.get("sample_count", 1)
        }
        
        # Veo 3 ç‰¹æ®Šåƒæ•¸
        if "veo-3" in model_id and model_info.get("supports_audio"):
            parameters["generateAudio"] = kwargs.get("generate_audio", True)
            parameters["resolution"] = kwargs.get("resolution", "720p")
        
        # é¸ç”¨åƒæ•¸
        optional_params = {
            "enhancePrompt": kwargs.get("enhance_prompt"),
            "negativePrompt": kwargs.get("negative_prompt"),
            "personGeneration": kwargs.get("person_generation"),
            "compressionQuality": kwargs.get("compression_quality"),
            "seed": kwargs.get("seed"),
            "storageUri": kwargs.get("storage_uri")
        }
        
        for key, value in optional_params.items():
            if value is not None:
                parameters[key] = value
        
        return {
            "instances": instances,
            "parameters": parameters
        }
    
    def create_image_to_video_payload(
        self,
        prompt: str,
        image_base64: str,
        mime_type: str,
        model_id: str,
        **kwargs
    ) -> Dict[str, Any]:
        """å‰µå»ºåœ–ç‰‡è½‰å½±ç‰‡çš„è«‹æ±‚è¼‰è·"""
        if model_id not in self.supported_models:
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹: {model_id}")
        
        model_info = self.supported_models[model_id]
        
        # å¸¶åœ–ç‰‡çš„å¯¦ä¾‹
        instances = [{
            "prompt": prompt,
            "image": {
                "bytesBase64Encoded": image_base64,
                "mimeType": mime_type
            }
        }]
        
        parameters = {
            "aspectRatio": kwargs.get("aspect_ratio", "16:9"),
            "durationSeconds": kwargs.get("duration_seconds", model_info["default_duration"]),
            "sampleCount": kwargs.get("sample_count", 1)
        }
        
        if "veo-3" in model_id and model_info.get("supports_audio"):
            parameters["generateAudio"] = kwargs.get("generate_audio", True)
            parameters["resolution"] = kwargs.get("resolution", "720p")
        
        return {
            "instances": instances,
            "parameters": parameters
        }
    
    def validate_request_structure(self, model_id: str, request_type: str) -> Dict[str, Any]:
        """é©—è­‰è«‹æ±‚çµæ§‹çš„æ­£ç¢ºæ€§"""
        results = {
            "model_id": model_id,
            "request_type": request_type,
            "endpoint": self.generate_api_endpoint(model_id),
            "polling_endpoint": self.generate_polling_endpoint(model_id),
            "supported_features": self.supported_models[model_id]
        }
        
        # æ¸¬è©¦ä¸åŒé¡å‹çš„è«‹æ±‚è¼‰è·
        if request_type == "text_to_video":
            payload = self.create_text_to_video_payload(
                prompt="æ¸¬è©¦æç¤ºï¼šä¸€éš»è²“åœ¨èŠ±åœ’è£¡ç©è€",
                model_id=model_id,
                duration_seconds=8,
                aspect_ratio="16:9"
            )
            results["sample_payload"] = payload
        
        elif request_type == "image_to_video":
            payload = self.create_image_to_video_payload(
                prompt="å°‡æ­¤åœ–ç‰‡è½‰ç‚ºå‹•ç•«",
                image_base64="fake_base64_data",
                mime_type="image/jpeg",
                model_id=model_id
            )
            results["sample_payload"] = payload
        
        return results


def run_structure_tests():
    """åŸ·è¡Œçµæ§‹æ¸¬è©¦"""
    print("ğŸ§ª Veo API çµæ§‹é©—è­‰æ¸¬è©¦")
    print("=" * 50)
    
    tester = VeoAPIStructureTest()
    
    # 1. é©—è­‰æ¨¡å‹æ”¯æ´
    print("\nğŸ“‹ 1. æ¨¡å‹æ”¯æ´é©—è­‰")
    model_stats = tester.validate_model_support()
    
    print(f"   ç¸½æ¨¡å‹æ•¸é‡: {model_stats['total_models']}")
    print(f"   ç©©å®šç‰ˆæœ¬: {len(model_stats['stable_models'])}")
    print(f"   é è¦½ç‰ˆæœ¬: {len(model_stats['preview_models'])}")
    print(f"   éŸ³è¨Šæ”¯æ´: {len(model_stats['audio_supported_models'])}")
    print(f"   åƒè€ƒåœ–ç‰‡: {len(model_stats['reference_image_models'])}")
    
    # 2. æ¨¡å‹è©³ç´°è³‡è¨Š
    print("\nğŸ“ 2. æ”¯æ´çš„æ¨¡å‹åˆ—è¡¨")
    for model_id, info in tester.supported_models.items():
        status_emoji = "âœ…" if info["status"] == "ç©©å®šç‰ˆæœ¬" else "ğŸ§ª"
        audio_emoji = "ğŸ”Š" if info.get("supports_audio", False) else "ğŸ”‡"
        ref_img_emoji = "ğŸ–¼ï¸" if info.get("supports_reference_images", False) else ""
        
        print(f"   {status_emoji} {model_id}")
        print(f"      åç¨±: {info['name']}")
        print(f"      ç‹€æ…‹: {info['status']} {audio_emoji} {ref_img_emoji}")
        print(f"      å½±ç‰‡é•·åº¦: {info['duration_range']} ç§’")
        print()
    
    # 3. API ç«¯é»é©—è­‰
    print("ğŸŒ 3. API ç«¯é»é©—è­‰")
    test_models = ["veo-2.0-generate-001", "veo-3.0-generate-001", "veo-3.0-fast-generate-001"]
    
    for model in test_models:
        print(f"\n   æ¨¡å‹: {model}")
        
        # ç”Ÿæˆç«¯é»
        endpoint = tester.generate_api_endpoint(model)
        print(f"   ç”Ÿæˆç«¯é»: {endpoint}")
        
        # è¼ªè©¢ç«¯é»
        polling = tester.generate_polling_endpoint(model)
        print(f"   è¼ªè©¢ç«¯é»: {polling}")
    
    # 4. è«‹æ±‚çµæ§‹é©—è­‰
    print("\nğŸ“¤ 4. è«‹æ±‚çµæ§‹é©—è­‰")
    
    # æ–‡å­—è½‰å½±ç‰‡è«‹æ±‚
    text_request = tester.validate_request_structure("veo-3.0-generate-001", "text_to_video")
    print("\n   æ–‡å­—è½‰å½±ç‰‡è«‹æ±‚ç¯„ä¾‹:")
    print("   ```json")
    print(json.dumps(text_request["sample_payload"], indent=2, ensure_ascii=False))
    print("   ```")
    
    # åœ–ç‰‡è½‰å½±ç‰‡è«‹æ±‚
    image_request = tester.validate_request_structure("veo-3.0-generate-001", "image_to_video")
    print("\n   åœ–ç‰‡è½‰å½±ç‰‡è«‹æ±‚ç¯„ä¾‹:")
    print("   ```json")
    # éš±è— base64 æ•¸æ“šä»¥ä¿æŒè¼¸å‡ºç°¡æ½”
    sample = image_request["sample_payload"].copy()
    sample["instances"][0]["image"]["bytesBase64Encoded"] = "[BASE64_IMAGE_DATA]"
    print(json.dumps(sample, indent=2, ensure_ascii=False))
    print("   ```")
    
    # 5. åƒæ•¸é©—è­‰
    print("\nâš™ï¸ 5. åƒæ•¸ç›¸å®¹æ€§é©—è­‰")
    
    veo2_features = ["aspectRatio", "durationSeconds", "sampleCount", "enhancePrompt", "negativePrompt"]
    veo3_features = veo2_features + ["generateAudio", "resolution"]
    
    print("   Veo 2.0 åƒæ•¸:", ", ".join(veo2_features))
    print("   Veo 3.0 æ–°å¢åƒæ•¸:", ", ".join(["generateAudio", "resolution"]))
    
    print("\nâœ… çµæ§‹é©—è­‰å®Œæˆï¼")
    print("\nğŸ“‹ ç¸½çµ:")
    print(f"   â€¢ æ”¯æ´ {len(tester.supported_models)} å€‹å®˜æ–¹æ¨¡å‹")
    print("   â€¢ API ç«¯é»æ ¼å¼æ­£ç¢º")
    print("   â€¢ è«‹æ±‚çµæ§‹ç¬¦åˆå®˜æ–¹æ–‡æª”")
    print("   â€¢ åƒæ•¸è¨­å®šå®Œæ•´æ”¯æ´")
    
    print("\nğŸš€ æº–å‚™ä½¿ç”¨çœŸå¯¦ Google Cloud èªè­‰é€²è¡Œæ¸¬è©¦ï¼")


if __name__ == "__main__":
    run_structure_tests()